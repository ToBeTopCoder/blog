分布式锁
分布式锁目前的实现方案，基于数据库实现分布式锁、基于缓存（redis，memcached，tair）实现分布式锁、基于Zookeeper实现分布式锁
# 数据库实现分布式锁 #
## 1、利用mysql的隔离性：唯一索引 ##
	我们先来看看表：
	CREATE TABLE `eleme_send_order` (
	  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT 'id',
	  `tracking_id` varchar(100) NOT NULL COMMENT '运单ID',
	  `push_time` bigint(20) NOT NULL COMMENT '推单时间',
	  `first_time` datetime DEFAULT NULL COMMENT '第一次记录时间',
	  `platform_id` int(4) NOT NULL COMMENT '帮买帮送运单类型',
	  `attempt_times` int(4) DEFAULT '0' COMMENT '尝试次数',
	  `update_time` datetime DEFAULT NULL COMMENT '更新时间',
	  `pull_tags` int(4) DEFAULT '0' COMMENT '拉取订单重试次数是否超标 0:否,1:是',
	  PRIMARY KEY (`id`),
	  UNIQUE KEY `uniq_tracking_id` (`tracking_id`)
	) ENGINE=InnoDB AUTO_INCREMENT=591 DEFAULT CHARSET=utf8 COMMENT='饿了么帮买帮送推单表';</code></pre>
	
	//数据库做幂等，tracking_id唯一索引，由数据库来保证只有一个操作成功
	try{
	   orderService.insertSendOrder(elemeSendOrderPO);
	}catch (DuplicateKeyException e){
	   //支持幂等 ignore
	}
## 2、利用数据库中排他锁 ##
首先了解下InnoDB行锁、表锁。
InnoDB行锁是通过给索引上的索引项加锁来实现的，只有通过索引条件检索数据，InnoDB才使用行级锁，否则InnoDB将使用表锁。

    获取锁       
	public boolean lock(){
	    connection.setAutoCommit(false)
	    while(true){
	        try{
	            result = select * from eleme_send_order where tracking_id=xxx for update;
	            if(result==null){
	            	//结果为空代表获取到锁
	                return true;
	            }
	        }catch(Exception e){

	        }
	        sleep(1000);
	    }
	    return false;
	}

	释放锁
	public void release(){
		connection.commit();
	}

这里还可能存在另外一个问题，虽然我们对tracking_id 使用了唯一索引，并且显示使用for update来使用行级锁。但是，MySql会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。
## 3、version 乐观锁  ##
即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表添加一个 “version”字段来实现读取出数据时，将此版本号一同读出，之后更新时，对此版本号加1。
在更新过程中，会对版本号进行比较，如果是一致的，没有发生改变，则会成功执行本次操作；如果版本号不一致，则会更新失败。

a. 先执行select操作查询当前数据的数据版本号,比如当前数据版本号是26：    
    select attempt_times, version from eleme_send_order  where attempt_times=1 and tracking_id=17812991;  
b. 执行更新操作：  
    update eleme_send_order set attempt_times=2, version=27, update_time=now() where tracking_id=17812991 and attempt_times=1 and version=26;

问题：  
a.这种操作方式，使原本一次的update操作，必须变为2次操作: select版本号一次；update一次。增加了数据库操作的次数。  
b.乐观锁机制往往基于系统中的数据存储逻辑，因此可能会造成脏数据被更新到数据库中。  
c.这些都基于数据库操作，在高并发的要求下，对数据库连接的开销一定是无法忍受的。
# 缓存Redis实现分布式锁 #
## 【错误方法】1、使用setnx()、expire()、del()方法 
首先说明一下setnx()命令，setnx的含义就是SET if Not Exists，其主要有两个参数 setnx(key, value)。该方法是原子的，如果key不存在，则设置当前key成功，返回1；如果当前key已经存在，则设置当前key失败，返回0。但是要注意的是setnx命令不能设置key的超时时间，只能通过expire()来对key设置。  
> 具体的使用步骤如下:  
    a. `setnx(lockkey, 1)`  如果返回0，则说明占位失败；如果返回1，则说明占位成功。  
    b. `expire()`命令对lockkey设置超时时间，为的是避免死锁问题。  
    c. 执行完业务代码后，可以通过`delete`命令删除key。  

这个方案其实是可以解决日常工作中的需求的，但从技术方案的探讨上来说，可能还有一些可以完善的地方。比如，如果在第一步setnx执行成功后，在expire()命令执行成功前，发生了宕机的现象，那么就依然会出现死锁的问题，所以如果要对其进行完善的话，可以使用redis的setnx()、get()和getset()方法来实现分布式锁。 
代码参考实例git：distributedLock.RedisLock (git地址文章最后)
## 【存在问题】2、使用setnx()、get()、getset()方法 ##
首先了解下getset()命令，这个命令主要有两个参数 `getset(key，newValue)`。该方法是原子的，对key设置newValue这个值，并且返回key原来的旧值。

> a. `setnx(lockkey, 当前时间+过期超时时间)` ，如果返回1，则获取锁成功；如果返回0则没有获取到锁。  
b. `get(lockkey)`获取值oldExpireTime ，并将这个value值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取。    
c. 计算`newExpireTime=当前时间+过期超时时间`，然后`getset(lockkey,newExpireTime)` 会返回当前lockkey的值currentExpireTime。    
d. 判断currentExpireTime与oldExpireTime 是否相等，如果相等，说明当前getset设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。  
e. 在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行delete释放锁；如果大于锁设置的超时时间，则不需要再锁进行处理。  
## 【推荐使用】3、Redis命令：SET key valueNX EX max-lock-time ##
> a.`set(keyName, lockValue, "NX", "EX", expireSeconds)` 如果返回OK，则获取锁成功；如果返回0则没有获取到锁。  
b.设置的value要有唯一性，来确保锁不会被误删(value=系统时间戳+UUID)。  
c.通过Lua命令来释放锁，保证原子性。eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令 `"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";`  
d.如果锁到达了最大生存时间将会自动释放。   

代码参考实例git：distributedLock.NewRedisLock   (git地址文章最后) 

如果你的项目中Redis是多机部署的，那么可以尝试使用Redisson实现分布式锁，这是Redis官方提供的Java组件，链接在参考阅读章节已经给出。

参考阅读

1、https://github.com/redisson/redisson

2、https://redis.io/commands/eval

3、https://redis.io/topics/distlock

#  基于Zookeeper实现分布式锁 #    
## 1、原生的Zookeeper实现 ##
> a.创建锁节点`/lock`，这个节点是每个要获取lock客户端共用的，节点设置为`PERSISTENT`。    
b.在/lock下创建临时的且有序的子节点，调用 `create()`，节点设置为`EPHEMERAL_SEQUENTIAL`，如第一个客户端对应的子节点为/lock/lock-0000000000，第二个为/lock/lock-0000000001，以此类推。  
c.在父锁节点上调用`getChildren()` ，不需要设置监视标志。 (为了避免“羊群效应”).    
d.按照Fair竞争的原则，在客户端获取/lock下的子节点列表，按照节点顺序的大小做排序，取出编号最小的一个节点做为lock的owner，判断自己的节点id是否就为owner id，如果是则返回，lock成功。如果不是则调用`exists()`监听比自己小的前一位的id，关注它锁释放的操作（也就是exist watch）。        
e.如果监听`exist`的watch被触发，则继续按照之前的原则判断自己是否能获取到lock。  
f.完成业务流程后，删除对应的子节点释放锁。

问题：假如当前有1000个节点在等待锁，如果获得锁的客户端释放锁时，这1000个客户端都会被唤醒，这种情况称为“羊群效应”；在这种羊群效应中，zookeeper需要通知1000个客户端，这会阻塞其他的操作，最好的情况应该只唤醒新的最小节点对应的客户端。    
在设置事件监听时，每个客户端应该对刚好在它之前的子节点设置事件监听，一个节点的删除只会导致一个客户端被唤醒，因为每个节点只被一个客户端watch，这避免了“羊群效应”。  

代码参考实例git：distributedLock.ZooKeeperLock   (git地址文章最后) 

## 2、可以用Curator轻易的实现一个分布式锁 ##
Curator不仅封装了Zookeeper的常用API，也包装了很多常用Case的实现。  

	InterProcessMutex lock = new InterProcessMutex(client, lockPath);
	//获得了锁, 进行业务流程
    Long maxWait = 10L;
    if ( lock.acquire(maxWait, TimeUnit.SECONDS) ){
        try{
		//获得了锁, 进行业务流程
        }finally{
            lock.release();
        }
    }

代码参考实例git：distributedLock.CuratorZookeeperLock   (git地址文章最后) 
基于Zookeeper实现分布式锁，其实是不常用的。虽然它实现锁十分优雅，但编程复杂，同时还要单独维护一套Zookeeper集群，频繁的Watch对Zookeeper集群的压力还是蛮大的，如果不是原有的项目以来Zookeeper，同时锁的量级比较小的话，还是不用为妙。

参考git地址  https://github.com/Sonion/JavaDemo.git   
